{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data import ZillowDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355c1820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading data...\n",
      "üßπ Cleaning property datasets...\n",
      "üõë Dropping 24 columns from Properties 2016 (>80.0% missing)\n",
      "üõë Dropping 24 columns from Properties 2017 (>80.0% missing)\n",
      "\n",
      "üîó Merging training data with property data\n",
      "‚úÖ Train 2016 shape: (90275, 20)\n",
      "‚úÖ Train 2017 shape: (77613, 20)\n",
      "‚úÇÔ∏è Filtering outliers in logerror...\n",
      "‚úÖ Data ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "# NOTE: change to local file storage\n",
    "processor = ZillowDataProcessor(\n",
    "    '/mnt/c/CS431/properties_2016.csv',\n",
    "    '/mnt/c/CS431/properties_2017.csv',\n",
    "    '/mnt/c/CS431/train_2016_v2.csv',\n",
    "    '/mnt/c/CS431/train_2017.csv'\n",
    ")\n",
    "\n",
    "processor.prepare()\n",
    "processed_df = processor.get_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b231f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['parcelid', 'logerror', 'transactiondate', 'bathroomcnt', 'bedroomcnt',\n",
      "       'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'fips',\n",
      "       'garagecarcnt', 'garagetotalsqft', 'lotsizesquarefeet',\n",
      "       'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity',\n",
      "       'regionidcounty', 'regionidzip', 'roomcnt', 'yearbuilt',\n",
      "       'numberofstories', 'taxamount'],\n",
      "      dtype='object')\n",
      "parcelid                          int64\n",
      "logerror                        float64\n",
      "transactiondate                   int64\n",
      "bathroomcnt                     float64\n",
      "bedroomcnt                      float64\n",
      "calculatedfinishedsquarefeet    float64\n",
      "finishedsquarefeet12            float64\n",
      "fips                            float64\n",
      "garagecarcnt                    float64\n",
      "garagetotalsqft                 float64\n",
      "lotsizesquarefeet               float64\n",
      "propertylandusetypeid           float64\n",
      "rawcensustractandblock          float64\n",
      "regionidcity                    float64\n",
      "regionidcounty                  float64\n",
      "regionidzip                     float64\n",
      "roomcnt                         float64\n",
      "yearbuilt                       float64\n",
      "numberofstories                 float64\n",
      "taxamount                       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed_df.columns)\n",
    "print(processed_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef15508",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = processed_df.drop(columns='logerror')\n",
    "label = processed_df['logerror'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a133402",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2af744",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b3e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_reggression import LinearModel\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee471f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearModel(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c04f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.model.predict(linear_model.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1149dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.007323446591417593\n",
      "Mean Squared Error: 0.006734180661252891\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(linear_model.y_test, y_pred)\n",
    "mse = mean_squared_error(linear_model.y_test, y_pred)\n",
    "print(f'R2 Score: {r2}')\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40876934",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58db108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM import LSTMModel\n",
    "from create_dataset import CreateDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3163c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64\n",
    "input_size = 19\n",
    "output_size = 1\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "dropout_rate = 0.3\n",
    "learning_rate = 0.001\n",
    "seq_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a48142",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(features, label, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataset = CreateDataset(X_train, y_train, seq_length)\n",
    "val_dataset = CreateDataset(X_val, y_val, seq_length)\n",
    "test_dataset = CreateDataset(X_test, y_test, seq_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bf4ad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 1/10, Loss: 0.0067\n",
      "Epoch 2/10, Loss: 0.0067\n",
      "Epoch 3/10, Loss: 0.0067\n",
      "Epoch 4/10, Loss: 0.0067\n",
      "Epoch 5/10, Loss: 0.0067\n",
      "Epoch 6/10, Loss: 0.0066\n",
      "Epoch 7/10, Loss: 0.0066\n",
      "Epoch 8/10, Loss: 0.0066\n",
      "Epoch 9/10, Loss: 0.0066\n",
      "Epoch 10/10, Loss: 0.0066\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, dropout_rate, output_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.00001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d41238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.0070732831954956055\n",
      "Mean Squared Error: 0.006735253147780895\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        preds.append(model(X_batch.to(device)).cpu().numpy())\n",
    "        actuals.append(y_batch.numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "actuals = np.concatenate(actuals)\n",
    "\n",
    "preds = np.array(preds).flatten()\n",
    "actuals = np.array(actuals).flatten()\n",
    "\n",
    "mse = mean_squared_error(actuals, preds)\n",
    "r2 = r2_score(actuals, preds)\n",
    "\n",
    "print(f'R2 Score: {r2}')\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
